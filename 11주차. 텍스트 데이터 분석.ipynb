{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텍스트 분석\n",
    "\n",
    "텍스트(비정형 데이터)로부터 정보를 추출해 내는 작업. 자연어 처리(NLP, Natural Language Processing)나 문서 처리 기술을 이용해서 정보를 추출을 해내는 작업이 먼저 선행이 된다.\n",
    "\n",
    "우선, 전처리 과정이 필요하다\n",
    "[전처리 과정]\n",
    "  - 텍스트 정규화 (Text Normalization)\n",
    "  - 텍스트 정규화란, 텍스트의 형태를 일관되게 변형하는 작업을 의미한다.\n",
    "      1. 토큰화(Tokenization) : 텍스트를 의미 단위(토큰)로 분할하는 작업\n",
    "      2. 어간 추출(Stemming) : 형태가 변현된 단어로부터 어간을 분리하는 작업 등이 포함된다.\n",
    "  - 형태소 분석(POS-Tagging)\n",
    "      1. 토큰으로 잘라낸 단어의 품사 정보들을 추출을 해내는 작업\n",
    "      \n",
    "이후, 텍스트 분석이 본격적으로 진행된다.\n",
    "\n",
    "#### 텍스트 분석의 종류\n",
    "\n",
    "    1. 정보 추출(Information Retrieval)\n",
    "        - 비정형 데이터인 문서(구조화 되지 않는 문서 군집 내에서) 안에서 필요한 정보를 포함하고 있는 정형 데이터의 형태의 정보를 추출해내는 작업\n",
    "    2. 문서 분류(Text Classification)\n",
    "        - 문서들을 특정 분류 체계에 따라 분류하는 작업\n",
    "        - EX) 뉴스가 정치 카테고리에 속하는지, 경제 카테고리에 속하는지 등과 같은 카테고리를 분류하는 작업\n",
    "    3. 감성 분석(Sentiment Analysis)\n",
    "        - 문서에 내포되어 있는 감정과 의견을 추출해내는 작업\n",
    "\n",
    "# 토큰화\n",
    "토큰화(tokenization) : 텍스트를 의미 단위로 분할하는 작업. 이렇게 분할한 결과물 단위를 토큰(token)이라고 함.\n",
    "\n",
    "Token : 텍스트 내부의 원소 (주어진 문장을 공백을 기준으로 단순 분할)\n",
    "Type : 추출된 토큰들 중에서 중복을 제외하고 (text), 어간이 같은 단어의 중복을 제외(had)\n",
    "\n",
    "[언어별 토큰화 방법]\n",
    " - 미국 : 단순 공백 기준 분할\n",
    " - 독일 : 복합명사에 대한 분리 방법이 요구됨\n",
    " - 중국 : 공백이 없으며 여러 문자로 한 단어가 이루어짐. 평균 2.4개의 문자들로 한 개의 단어가 구성\n",
    " - 한국 : 단순 공백 기준이 아닌 '품사' 기준으로 토큰화. 영어보다 조금 더 세밀한 작업들이 필요하다.\n",
    "     - 한국어를 토큰화하는 예시 문장입니다 -> 한국어, 를, 토큰화, 하다, 예시, 문장, 입, 니다\n",
    "     \n",
    "# 어간 추출(stemming)\n",
    "토큰화를 진행한 뒤에는 정확한 의미 파악을 위해서 어간 추출을 진행한다. 여기서 문장 속에 다양한 형태로 변형된 단어의 표제어(lemma)를 찾는  Lemmatization이라는 작업이 진행된다. \n",
    "    - 표제어 : 단어의 의미를 사전에서 찾을 때 사용하는 기본형 \n",
    "![스크린샷, 2017-11-19 23-16-41](https://i.imgur.com/swbGIUj.png)\n",
    "   - Stemming : 단어의 의미를 이해하지 않는다.\n",
    "   - Lemmatization : 날다(동사)인지, 파리(명사)인지 파악\n",
    "   \n",
    "의미를 파악한 후, 어간을 추출한다. 즉, 형태가 변형된 단어에 대해 접사 등을 제거하고 어간을 분리해 내는 작업이다.\n",
    "EX1) fly, flying, flies -> fly\n",
    "EX2) stemming, stemmed, stemmer -> stem\n",
    "    \n",
    "`영어`의 어간 추출하는 대표적인 알고리즘은 `포터 알고리즘`이다.\n",
    "\n",
    "\n",
    "## 포터 알고리즘\n",
    "\n",
    "![스크린샷, 2017-11-19 23-20-16](https://i.imgur.com/I8JRwFO.png)\n",
    "\n",
    "\n",
    "1. Step 1a\n",
    "    - 어간을 추출하기 위해 명사의 복수형을 단수형으로 고치기 위한 규칙을 적용\n",
    "    - 명사의 복수형을 단수형으로 고친다.\n",
    "    - 추상명사는 단수와 복수의 구분이 없기 때문에 변화가 없다(caress->caress)\n",
    "    - 복수형을 만들기 위해서 흔히 사용하는 s는 생략해 단수형으로 만든다(cats->cat)\n",
    "\n",
    "    ![스크린샷, 2017-11-19 23-23-27](https://i.imgur.com/Cw5opG3.png)\n",
    "2. Step 1b, 1b1\n",
    "    - 동사를 원형으로 변환하고, 단어의 품사가 바뀌면서 단어가 변형된 경우에 그 단어의 기본형으로 다시 바꿔준다.\n",
    "    ![스크린샷, 2017-11-19 23-23-54](https://i.imgur.com/BZu2CA6.png)\n",
    "\n",
    "3. Step2\n",
    "    - 단어의 의미의 변형이 일어나는 경우 다시 기본형으로 바꿔준다.\n",
    "\n",
    "# 형태소 분석\n",
    "토큰의 품사 정보를 추출하는 작업. \n",
    "    EX) Jane Plays well with her friends.\n",
    "    -> Jane (NNP), play(VB), well(RB), her(PRP), friends(NNS\n",
    "    \n",
    "## Open Class vs. Closed Class\n",
    "\n",
    "![스크린샷, 2017-11-19 23-28-25](https://i.imgur.com/SUKtM0W.png)\n",
    "Open Class : 명사, 동사, 형용사, 부사 등 새로운 단어의 등장이 상대적으로 많은 품사등을 의미한다.\n",
    "\n",
    "![스크린샷, 2017-11-19 23-27-14](https://i.imgur.com/4kaXyjE.png)\n",
    "Closed Class : 상대적으로 새로운 단어가 잘 추가되지 않는 고정된 세트. 문장 내에서 주로 문법적인 역할을 수행한다.\n",
    "\n",
    "## 형태소 분석기\n",
    "\n",
    "영어 :Standford POS-Tagger, NLTK Pos-Tagger\n",
    "\n",
    "한국어 : Han nanum, Kkma, Komoran, Twitter\n",
    "\n",
    "# 정보 추출\n",
    "구조화 되지 않는 문서 군집 내에서 필요한 정보를 포함하고 있는 문서를 찾아내는 작업 (문서라기 보다는, 구조화된 데이터, 정형 데이터, 즉 테이블 형태로 표현이 될 수 있는 데이터를 의미한다.) 우리가 흔히 인터넷에서 검색을 하는 것도 일종의 정보 추출이라고 할 수 있다.\n",
    "\n",
    "\n",
    "\n",
    "1. 문서 단어 행렬(document term matrix)\n",
    "    ![스크린샷, 2017-11-19 23-31-18](https://i.imgur.com/wSwyzm2.png)\n",
    "    - 이 행렬에서 **1** 은 해당 단어가 해당 문서에 등장한다는 뜻이다. **0**은 해당 단어가 해당 문서에 등장하지 않는다는 뜻이다.\n",
    "    - 각 단어는 벡터로 푠현이 가능하다.\n",
    "    - Circket과 Princess는 포함하되 Pinocchio는 포함하지 않는다는 조건의 벡터 연산이 가능하다. (Cricket AND Princess AND NOT Pinocchio)\n",
    "    - 문서와 단어의 수가 증가하면 **sparse matrix(값의 대부분이 0인 행렬) ** 가 생성된다.\n",
    "    \n",
    "2. 각 단어가 문서에 몇 번 등장하는지 빈도를 보여주는 행렬\n",
    "    ![스크린샷, 2017-11-19 23-34-20](https://i.imgur.com/silzLzF.png)\n",
    "    - 문서는 단어의 등장 빈도를 나타내는 **count vector** 로 표현될 수 있다.\n",
    "    - Bag of Words 모델 : 문서 내에 등장하는 단어들의 순서를 무시한다.\n",
    "        - John is quicker than Mary vs Mary is quicker than John : 이 문장은 같은 벡터를 가지고 있다. 등장하는 단어의 순서는 고려하지 않는다.\n",
    "        \n",
    "3. Term Frequence(TF\n",
    "    - 각 단어가 문서 내에서 정말 중요한 단어인가?\n",
    "    - 단어 빈도 tft, d는 특정 단어 t가 특정 문서 d 내에 등장하는 빈도를 의미한다.\n",
    "        - 특정단어가 10번 등장하는(tf=10) 문서가 1번 등장하는 **(tf=1) 문서보다 더 많이 타당**하다고 볼 수 없다.\n",
    "        - tf값이 크담녀 이 단어는 특정 문서에 더 많이 등장한다는 뜻이다. 하지만 특정 단어가 10번 등장하는 문서가 1번 밖에 등장하지 않는 문서보다 더 적합하거나 타당하다고 보기 어렵다.\n",
    "        - 예를 들어서, good, increase, high, of, the, a와 같은 단어는 많이 나오더라도 그 문서의 의미를 다른 의미와 구별하기 쉽지 않다.\n",
    "        - 오히려 드물게 등장하는 단어가 하나의 문서를 다른 문서와 더 구별하는 데 유용하게 사용될 수 있다.\n",
    "        - `Back-propagation`(즉, 역전파)와 같은 단어가 이 문서와 다른 문서와 차별화시키는 좋은 예가 될 수 있다.\n",
    "            - 드문 단어들에 대해 가중치를 부여할 필요성이 있다는 개념을 도입한 용어가 **Inverse Document Frequency(IDF)** 이다.\n",
    "            \n",
    "4. Inverse Document Frequence (IDF)\n",
    "    ![스크린샷, 2017-11-19 23-41-51](https://i.imgur.com/9Mnyy9Y.png)\n",
    "    - df(=document requency) : 단어 t가 등장한 문서의 수\n",
    "    - dft는 단어 **t의 중요도의 역수**와 같다.\n",
    "    - 단어 t의 idf 수치 idft는 t의 **단어의 중요도를 나타내는 척도**\n",
    "    - the와 같은 정관사는 df의 값이 높다. 반대로 Barbossa(캐리비안 해적에 나오는 캐릭터)는 다른 문서에서 나오기 힘들다. 그래서 다른 문서와 구별하는 데 큰 역할을 할 수 있다.\n",
    "    ![스크린샷, 2017-11-19 23-43-16](https://i.imgur.com/IMCxZUS.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
