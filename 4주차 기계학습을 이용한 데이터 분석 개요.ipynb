{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 머신러닝\n",
    "\n",
    "기계학습이라고도 불림. 인공지느으이 핵심 기술. 명시적인 프로그램이 없어도 컴퓨터가 학습할 수 있다는 것이 머신 러닝의 가장 큰 특징이다.\n",
    "컴퓨터 프로그램은 어떤 작업의 성능이 '경험'을 통해서 향상되면 이것을 '학습'이라고 부른다.\n",
    "\n",
    "# 머신러닝 용어\n",
    "\n",
    "1. 특징(Feature, 자질)\n",
    "  각각의 아이템을 설명하는 데 사용하는 구분 가능한 특성 또는 특징의 개수 EX) 자동차와 오토바이의 차이점은 '바퀴의 개수' 또는 '크기'임.\n",
    "  <br>\n",
    "2. 데이터(Data)\n",
    "    학습이나 예측에 사용하는 원시 자료, 또는 가공된 자료 EX) 문서, 사진, 음성, 동영상, 데이터베이스, 엑셀파일\n",
    "    <br>\n",
    "3. 특징 벡터(Feature Vector)\n",
    "    대상을 표현하는 특징으로 이루어진 N차원의 벡터 EX) 자동차와 오토바이의 차이점(특징)이 100개가 있으면 100차원 벡터를 만들 수 있다.\n",
    "    <br>\n",
    "\n",
    "4. 특징 추출(Feature Extraction)\n",
    "  성능향상 : 벡터의 차원, but 속도 down => 차원 감소 기법 사용(주성분 분석='PCA')\n",
    "  <br>\n",
    "\n",
    "5. 학습 셋(Training Set)\n",
    "    학습에 사용하는 데이터 셋 EX) 개와 고양이를 구분짓는 특징?\n",
    "\n",
    "\n",
    "# 머신러닝 흐름도\n",
    "머신 러닝 기법 중에서 교사학습(supervise learning)\n",
    "크게 학습과정과 예측 과정으로 나눌 수 있음.\n",
    "\n",
    "## 학습과정\n",
    "데이터가 입력되면 데이터 특징을 추출한다. 이렇게 추출된 특징들을 머신러닝 알고리즘에 입력하면 그 결과로 모델이 생성된다. 이 모델은 예측 또는 분류 등의 역할을 할 수가 있다.\n",
    "\n",
    "##예측과정\n",
    "이렇게 만들어진 모델을 가지고 예측을 하는 과정을 보게 되면 학습과정과 비슷하게 구성이 된다. 학습단계에서 만들어진 모델을 사용해서 예측을 하기 전에는 라벨 정보가 없고 분류 결과로 라벨을 출력한다. 이렇게 만들어진 머신 러닝 분류기는 성능 측정과 최적화 과정을 거쳐서 성능을 점점 높이게 된다. 또한 분류 모델은 한번 만들어놓고 영원히 사용하는 것이 아니라 데이터가 추가되거나 또는 데이터가 바뀌거나 함에 따라서 주기적으로 업데이트 해줘야 성능이 향상된다.\n",
    "\n",
    "# 머신러닝 카테고리\n",
    "1. 교사 학습\n",
    "    학습 데이터의 정확한 클래스가 알려져있는 학습 방식\n",
    "    장점 : 비교사 학습에 비해 적은 비용\n",
    "    단점 : 수작업으로 클래스 입력\n",
    "    <br>    \n",
    "2. 비교사 학습\n",
    "    학습 데이터의 정확한 클래스가 알려져 있지 않을 때 사용\n",
    "    장점 : 수작업으로 클래스 입력의 번거로움이 없음\n",
    "    단점 : 결과 확인의 비용 과다 발생\n",
    "    <br>\n",
    "3. 반교사 학습\n",
    "    교사학습 + 비교사학습, 클래스 일부 입력만으로 결과를 자동으로 분석\n",
    "    <br>\n",
    "4. 강화 학습\n",
    "    에이전트(agent)가 환경으로부터의 피드백을 기반으로 해서 동작을 학습하는 방법을 말한다. 실패했을 때는 피드백을, 성공했으면 피드백해서 보상을 주게 된다. 이러한 '시행착오'를 거쳐서 학습을 하면서 보다 정하고한 목표를 달성하고 다음 레벨을 반복하여 점점 더 성능을 올리는 방법이다.\n",
    "\n",
    "# 머신러닝 기술적용 분야\n",
    "\n",
    "1. 분류(classification)\n",
    "    데이터(텍스트, 이미지)로부터 클래스 예측한다. 미리 정의된 카테고리로 데이터 분류\n",
    "    EX1) 정치, 경제, 사회, 문화 뉴스 카테고리\n",
    "    EX2) 일반종양과 악성종약 분류\n",
    "    EX3) 스팸메일 /비스팸메일\n",
    "    EX4) 긍정 / 부정\n",
    "\n",
    "    가장 대중적 분류 알고리즘 : 나이브 베이즈, 랜덤 포레스트, 서포트 벡터 머신 (여기서는 나이브 베이즈만)\n",
    "\n",
    "    ## 나이브 베이즈\n",
    "      1단계 : 카테고리가 있는 학습 데이터 사용해 모델 만ㄷ름. 카테고리에 해당할 확률을 구함\n",
    "      2단계 : 테스트 데이터로 테스트해 성능을 측정해 성능이 만족스럽다면 분류기로 사용하고, 아닐 경우 알고리즘을 바꾸거나 특정값을 바꾼다.\n",
    "<br>\n",
    "\n",
    "2. 군집(clustering)\n",
    "    데이터로부터 서로 더 비슷한 집합을 동일한 그룹(=군집)으로 그룹화한다. 개체는 사전에 미리 정의되어 있지 않다.\n",
    "    EX) 1반남자, 1반여자 / 2반남자, 2반 여자도 가능하지만\n",
    "\n",
    "    가장 대중적인 알고리즘 : K-MEANS 군집, 계층적 군집\n",
    "\n",
    "    ## K-MEANS 군집\n",
    "        K개 군집으로 N개의 관측치 분할\n",
    "\n",
    "    ## 계층적 군집\n",
    "        군집 계층을 구축하고 찾는 군집 분석 방법\n",
    "\n",
    "        병합 : 상향식 접근 방법, 계층 구조가 올라감에 따라 병합하지만 시간 복잡도가 높다.\n",
    "        분열 : 하향식 접근 방법, 계층 구조가 내려감에 따라 재귀적으로 수행된다.\n",
    "  <br>\n",
    "\n",
    "3. 회귀(regression)\n",
    "    하나의 변수 평균값과 다른 변수 해당 값간 관계를 측정한다.\n",
    "    변수 간의 관계 추정 위한 통계인데, 학습 데이터 이용해 결과값을 예측한다.\n",
    "\n",
    "    * 가장 대중적인 회귀 : 선형 회귀, 로지스틱 회귀\n",
    "\n",
    "    분류(classification) : 결과를 클래스로 그룹화 (사기거래/정상거래 분류),     데이터가  이산/범주형 변수\n",
    "    회귀(regression) : 출력값 예측 (거시 경제 예측, 주식/부동산 가격 예측 등), 데이터가 실수/연속형 변수\n",
    "\n",
    "\n",
    "\n",
    "# 머신러닝 사용 예\n",
    "\n",
    "\n",
    "스팸 메일 분류, 주가 예측, 기계 번역, 텍스트 요약, 사기 탐지, 감성 분석, 음성 분석, 얼굴 인식 등..\n",
    "\n",
    "Toyota Corolla 중고차 가격 예측\n",
    "    데이터 : **차의 특징** (가격, 연식, 주행거리, 연료타입, 배기량 등 11개)에 따라 Toyota Corolla 중고차 1,442대 가격을 예측했다. 처음에 **상관관계 분석** 을 통해 특징 선정 여기서 상관관계가 낮은 특징은 제외하고 8개의 특징만 사용했다,\n",
    "\n",
    "\n",
    "# 웹 마이닝\n",
    "인터넷 상에서 수집된 정보를 기존의 데이터 마이닝 방법으로 분석 및 통합하는 기술. 웹 마니잉은 고객의 취향을 이해하고 특정 웹사이트의 효능을 평가하여 마케팅의 질적 향상을 도모하기 위해 사용되고 있다.\n",
    "\n",
    "\n",
    "\n",
    "# 정리\n",
    "\n",
    "머신러닝이란 기계가 학습하는 것을 말하며, 명시적인 프로그램 없이 컴퓨터가 학습이 가능하다는 것이 머신러닝의 가장 큰 특징으로 볼 수 있습니다.\n",
    "\n",
    "머신러닝의 기술은 세 가지 적용 분야로 나눌 수 있다.\n",
    "    1. 분류 : 데이터로부터 클래스를 나누는 작업 즉 데이터로부터 그러한 카테고리를 예측하는 기술이 있습니다.\n",
    "    2. 군집 : 데이터로부터 의미 있는 그룹을 나눈 기술\n",
    "    3. 회귀 : 데이터 분석을 통해서 값을 예측\n",
    "\n",
    "또한, 머신러닝은 다양한 분야에서 활용되고 있습니다.\n",
    "이러한 머신러닝을 활용한 데이터 분석은 특징에 따라 데이터를 사용하고, 해당 데이터는 예측하기 전에 **상관관계 분석** 을 통해 특징을 선정하게 됩니다.\n",
    "그런 다음, **머신러닝** 을 통해 **회귀식** 을 도출한 뒤, 회귀식에 대한 **성능평가** 를 진행합니다.\n",
    "마지막으로 해당 데이터에 필요한 예측기를 만들었다면 데이터에 적용해 보는 것으로 데이터 분석을 마무리할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 머신러닝\n",
    "\n",
    "기계학습이라고도 불림. 인공지느으이 핵심 기술. 명시적인 프로그램이 없어도 컴퓨터가 학습할 수 있다는 것이 머신 러닝의 가장 큰 특징이다.\n",
    "컴퓨터 프로그램은 어떤 작업의 성능이 '경험'을 통해서 향상되면 이것을 '학습'이라고 부른다.\n",
    "\n",
    "# 머신러닝 용어\n",
    "\n",
    "1. 특징(Feature, 자질)\n",
    "  각각의 아이템을 설명하는 데 사용하는 구분 가능한 특성 또는 특징의 개수 EX) 자동차와 오토바이의 차이점은 '바퀴의 개수' 또는 '크기'임.\n",
    "  <br>\n",
    "2. 데이터(Data)\n",
    "    학습이나 예측에 사용하는 원시 자료, 또는 가공된 자료 EX) 문서, 사진, 음성, 동영상, 데이터베이스, 엑셀파일\n",
    "    <br>\n",
    "3. 특징 벡터(Feature Vector)\n",
    "    대상을 표현하는 특징으로 이루어진 N차원의 벡터 EX) 자동차와 오토바이의 차이점(특징)이 100개가 있으면 100차원 벡터를 만들 수 있다.\n",
    "    <br>\n",
    "\n",
    "4. 특징 추출(Feature Extraction)\n",
    "  성능향상 : 벡터의 차원, but 속도 down => 차원 감소 기법 사용(주성분 분석='PCA')\n",
    "  <br>\n",
    "\n",
    "5. 학습 셋(Training Set)\n",
    "    학습에 사용하는 데이터 셋 EX) 개와 고양이를 구분짓는 특징?\n",
    "\n",
    "\n",
    "# 머신러닝 흐름도\n",
    "머신 러닝 기법 중에서 교사학습(supervise learning)\n",
    "크게 학습과정과 예측 과정으로 나눌 수 있음.\n",
    "\n",
    "## 학습과정\n",
    "데이터가 입력되면 데이터 특징을 추출한다. 이렇게 추출된 특징들을 머신러닝 알고리즘에 입력하면 그 결과로 모델이 생성된다. 이 모델은 예측 또는 분류 등의 역할을 할 수가 있다.\n",
    "\n",
    "##예측과정\n",
    "이렇게 만들어진 모델을 가지고 예측을 하는 과정을 보게 되면 학습과정과 비슷하게 구성이 된다. 학습단계에서 만들어진 모델을 사용해서 예측을 하기 전에는 라벨 정보가 없고 분류 결과로 라벨을 출력한다. 이렇게 만들어진 머신 러닝 분류기는 성능 측정과 최적화 과정을 거쳐서 성능을 점점 높이게 된다. 또한 분류 모델은 한번 만들어놓고 영원히 사용하는 것이 아니라 데이터가 추가되거나 또는 데이터가 바뀌거나 함에 따라서 주기적으로 업데이트 해줘야 성능이 향상된다.\n",
    "\n",
    "# 머신러닝 카테고리\n",
    "1. 교사 학습\n",
    "    학습 데이터의 정확한 클래스가 알려져있는 학습 방식\n",
    "    장점 : 비교사 학습에 비해 적은 비용\n",
    "    단점 : 수작업으로 클래스 입력\n",
    "    <br>    \n",
    "2. 비교사 학습\n",
    "    학습 데이터의 정확한 클래스가 알려져 있지 않을 때 사용\n",
    "    장점 : 수작업으로 클래스 입력의 번거로움이 없음\n",
    "    단점 : 결과 확인의 비용 과다 발생\n",
    "    <br>\n",
    "3. 반교사 학습\n",
    "    교사학습 + 비교사학습, 클래스 일부 입력만으로 결과를 자동으로 분석\n",
    "    <br>\n",
    "4. 강화 학습\n",
    "    에이전트(agent)가 환경으로부터의 피드백을 기반으로 해서 동작을 학습하는 방법을 말한다. 실패했을 때는 피드백을, 성공했으면 피드백해서 보상을 주게 된다. 이러한 '시행착오'를 거쳐서 학습을 하면서 보다 정하고한 목표를 달성하고 다음 레벨을 반복하여 점점 더 성능을 올리는 방법이다.\n",
    "\n",
    "# 머신러닝 기술적용 분야\n",
    "\n",
    "1. 분류(classification)\n",
    "    데이터(텍스트, 이미지)로부터 클래스 예측한다. 미리 정의된 카테고리로 데이터 분류\n",
    "    EX1) 정치, 경제, 사회, 문화 뉴스 카테고리\n",
    "    EX2) 일반종양과 악성종약 분류\n",
    "    EX3) 스팸메일 /비스팸메일\n",
    "    EX4) 긍정 / 부정\n",
    "\n",
    "    가장 대중적 분류 알고리즘 : 나이브 베이즈, 랜덤 포레스트, 서포트 벡터 머신 (여기서는 나이브 베이즈만)\n",
    "\n",
    "    ## 나이브 베이즈\n",
    "      1단계 : 카테고리가 있는 학습 데이터 사용해 모델 만ㄷ름. 카테고리에 해당할 확률을 구함\n",
    "      2단계 : 테스트 데이터로 테스트해 성능을 측정해 성능이 만족스럽다면 분류기로 사용하고, 아닐 경우 알고리즘을 바꾸거나 특정값을 바꾼다.\n",
    "<br>\n",
    "\n",
    "2. 군집(clustering)\n",
    "    데이터로부터 서로 더 비슷한 집합을 동일한 그룹(=군집)으로 그룹화한다. 개체는 사전에 미리 정의되어 있지 않다.\n",
    "    EX) 1반남자, 1반여자 / 2반남자, 2반 여자도 가능하지만\n",
    "\n",
    "    가장 대중적인 알고리즘 : K-MEANS 군집, 계층적 군집\n",
    "\n",
    "    ## K-MEANS 군집\n",
    "        K개 군집으로 N개의 관측치 분할\n",
    "\n",
    "    ## 계층적 군집\n",
    "        군집 계층을 구축하고 찾는 군집 분석 방법\n",
    "\n",
    "        병합 : 상향식 접근 방법, 계층 구조가 올라감에 따라 병합하지만 시간 복잡도가 높다.\n",
    "        분열 : 하향식 접근 방법, 계층 구조가 내려감에 따라 재귀적으로 수행된다.\n",
    "  <br>\n",
    "\n",
    "3. 회귀(regression)\n",
    "    하나의 변수 평균값과 다른 변수 해당 값간 관계를 측정한다.\n",
    "    변수 간의 관계 추정 위한 통계인데, 학습 데이터 이용해 결과값을 예측한다.\n",
    "\n",
    "    * 가장 대중적인 회귀 : 선형 회귀, 로지스틱 회귀\n",
    "\n",
    "    분류(classification) : 결과를 클래스로 그룹화 (사기거래/정상거래 분류),     데이터가  이산/범주형 변수\n",
    "    회귀(regression) : 출력값 예측 (거시 경제 예측, 주식/부동산 가격 예측 등), 데이터가 실수/연속형 변수\n",
    "\n",
    "\n",
    "\n",
    "# 머신러닝 사용 예\n",
    "\n",
    "\n",
    "스팸 메일 분류, 주가 예측, 기계 번역, 텍스트 요약, 사기 탐지, 감성 분석, 음성 분석, 얼굴 인식 등..\n",
    "\n",
    "Toyota Corolla 중고차 가격 예측\n",
    "    데이터 : **차의 특징** (가격, 연식, 주행거리, 연료타입, 배기량 등 11개)에 따라 Toyota Corolla 중고차 1,442대 가격을 예측했다. 처음에 **상관관계 분석** 을 통해 특징 선정 여기서 상관관계가 낮은 특징은 제외하고 8개의 특징만 사용했다,\n",
    "\n",
    "\n",
    "# 웹 마이닝\n",
    "인터넷 상에서 수집된 정보를 기존의 데이터 마이닝 방법으로 분석 및 통합하는 기술. 웹 마니잉은 고객의 취향을 이해하고 특정 웹사이트의 효능을 평가하여 마케팅의 질적 향상을 도모하기 위해 사용되고 있다.\n",
    "\n",
    "\n",
    "\n",
    "# 정리\n",
    "\n",
    "머신러닝이란 기계가 학습하는 것을 말하며, 명시적인 프로그램 없이 컴퓨터가 학습이 가능하다는 것이 머신러닝의 가장 큰 특징으로 볼 수 있습니다.\n",
    "\n",
    "머신러닝의 기술은 세 가지 적용 분야로 나눌 수 있다.\n",
    "    1. 분류 : 데이터로부터 클래스를 나누는 작업 즉 데이터로부터 그러한 카테고리를 예측하는 기술이 있습니다.\n",
    "    2. 군집 : 데이터로부터 의미 있는 그룹을 나눈 기술\n",
    "    3. 회귀 : 데이터 분석을 통해서 값을 예측\n",
    "\n",
    "또한, 머신러닝은 다양한 분야에서 활용되고 있습니다.\n",
    "이러한 머신러닝을 활용한 데이터 분석은 특징에 따라 데이터를 사용하고, 해당 데이터는 예측하기 전에 **상관관계 분석** 을 통해 특징을 선정하게 됩니다.\n",
    "그런 다음, **머신러닝** 을 통해 **회귀식** 을 도출한 뒤, 회귀식에 대한 **성능평가** 를 진행합니다.\n",
    "마지막으로 해당 데이터에 필요한 예측기를 만들었다면 데이터에 적용해 보는 것으로 데이터 분석을 마무리할 수 있습니다.\n",
    "\n",
    "\n",
    "# 예측모델 성능평가\n",
    "\n",
    "## 데이터 셋 구성을 통한 검증방법\n",
    "![스크린샷, 2017-09-21 09-23-02](https://i.imgur.com/5N9bvUo.png)\n",
    "\n",
    "Training Set에서 훈련된 모델의 성능을 Validation Set을 사용해 검증하고, 모델이 적절하지 못할 경우에 다시 학습을 시켜 최적의 모델이 도출될 때까지 반복한다. 최종 모델이 도출되면 Test Set을 사용해서 모델의 최종 성능을 평가해본다.\n",
    "\n",
    "## 데이터셋 준비방법\n",
    "\n",
    "### Holdout\n",
    "1. 훈련용 데이터\n",
    "2. 테스트용 데이터\n",
    "\n",
    "![스크린샷, 2017-09-21 09-27-41](https://i.imgur.com/nZQKPTH.png)\n",
    "단순히 데이터 셋을 위와 같이 두 개 또는 세 개로 나누어서 사용하는 방법\n",
    "Training Set이 좀 작아지고, Test Set이 만약 커진다면 모델의 훈련 정도가 부족하기 때문에 모델의 성능이나 정확도의 분산이 커지는 문제가 발생한다.\n",
    "![스크린샷, 2017-09-21 09-28-21](https://i.imgur.com/2HHHf9z.png)\n",
    "만약 Training Set이 커지고, Test Set이 작아지면 적절한 서능평가가 이루어지기 힘들다. 따라서 측정 모델의 정확도에 대한 신뢰도가 떨어진다는 문제가 발생한다. 이를 극복하기 위해서 Random Subampling을 사용한다.\n",
    "\n",
    "### Random Subsampling\n",
    "![스크린샷, 2017-09-21 09-29-51](https://i.imgur.com/QMYmrz6.png)\n",
    "Random Subsampling : Holdout을 반복한다. 각 실험마다 랜덤으로 추출한 데이터 셋을 사용하고 성능을 평가하면 각 실험 성능들의 평균으로 도출된다.\n",
    "\n",
    "### K fold Cross Validation\n",
    "데이터 셋을 중복하지 않고 k개로 나누어서, k개의 데이터 셋으로 나누어 구성하는 방법이다. k개의 교차검증. 전체 데이터 셋을 k개(예를 들어 10개)로 나누어서 사욯한다. k가 10개라고 한다면 k-1개, 즉 9개를 Train Set으로 사용을하고, 나머지 한 개의 Set을 사용해서 모델의 성능을 테스트한다.\n",
    "![스크린샷, 2017-09-21 09-33-22](https://i.imgur.com/iyz9KM4.png)\n",
    "이 방법은 Test Set과 Training Set을 매번 다르게 구성해서, 여러 번의 실험을 진행한다는 점이 앞의 Random Subsampling과 유사하다. 하지만 k fold Cross Validation은 전체 데이터를 `균일`하게 나누어서 사용하기 때문에 모든 데이터를 train과, 즉 훈련과 검증에 적용할 수 있다는 장점이 있다.\n",
    "\n",
    "이 방법에서도 마찬가지로 각 실험에서 계산된 선능들의 `평균`을 모델의 최종 성능으로 도출한다.\n",
    "\n",
    "### Stratified Sampling\n",
    "층별 표집방법이라고 불리는 이 방법은 데이터를 구성하는 각 동일한 집단으로부터 각각 일정 비율의 샘플을 추출하는 방법이다. 우선 데이터를 클래스에 따라서 각 그룹으로 분리한다. 그리고 각 그룹으로부터 일정 비율의 샘플을 무작위로 추출을 한다. 만야 전체 데이터 셋에서 무작위로 샘플을 추출할 경우에는 특정 클래스에 데이터가 편중될수 있지만, 이 방법을 사용하면 각 클래스마다 샘플을 추출하기 때문에 샘플의 대표성을 높일 수 있는 장점이 있다.\n",
    "\n",
    "### Bootstrap\n",
    "![스크린샷, 2017-09-21 09-36-14](https://i.imgur.com/hgnCqml.png)\n",
    "앞의 방법과 조금 다르게, 샘플을 추출할 때 중복 추출을 허용한다. 전체 데이터 셋에서 n개의 샘플을 추출하는 실험을 여러 번 진행하는데, 동일 샘플이 실험마다 중복되서 사용될 수도 있다. 이렇게 중복을 허용해 샘플을 반복적으로 추출해 실험을 진행하고, 최종 성능은 실험들의 평균으로 도출된다.\n",
    "\n",
    "\n",
    "## 모델성능 평가 척도\n",
    "![스크린샷, 2017-09-21 09-37-25](https://i.imgur.com/W2Q2fHx.png)\n",
    "1. Confusion Matrix\n",
    "![스크린샷, 2017-09-21 09-39-14](https://i.imgur.com/SaMsJlO.png)\n",
    "  모델의 성능을 수치로 시각화한다. 세로축은 데이터의 실제 클래스, 그리고 가로축은 모델이 예측한 클래스로, 각 위치에 해당되는 데이터의 건수가 입력이 된다. 즉 a는 실제 yes 카테고리의 데이터 중에서 모델이 yes 카테고리로 예측한 데이터의 건수다. 이것을 `True Positive`라고 하기도 하고 약자인 `TP`로 표현하기도 한다.\n",
    "\n",
    "  b는 실제 yes 카테고리 데이터 중에서 모델이 no 카테고리로 잘못 예측된 데이터의 건수를 표시한다. 즉, 이렇게 잘못 예측된 것을 `False Negative`라고 하며 약자로 `FN`으로 표시하기도 한다. c셀은 실제 no 카테고리의 데이터 중에서 모델이 yes 카테고리로 잘못 예측한 데이터의 건수로서 `False Positive`가 되고, 약자로 FP라고 표시하기도 한다. d셀에는 실제 no 카테고리의 데이터 중에서 모델이 no 카테고리라고 해서 제대로 예측을 했다면 그 건수를 표시를 한다.\n",
    "  ![스크린샷, 2017-09-21 09-42-08](https://i.imgur.com/Tgee7Qk.png)\n",
    "  이렇게 4가지로 Confusion Matix를 구성을 해서 모델의 예측 결과를 통계적으로 살펴볼 수 있다.\n",
    "2. 정확도(Accuracy)\n",
    "![스크린샷, 2017-09-21 09-42-50](https://i.imgur.com/ZNuT827.png)\n",
    "  모델이 올바르게 분류가 되는지에 대한 데이터의 비율을 의미. 그러나 문제점이 있다.\n",
    "\n",
    "  우리의 모델이 모든 데이터를 Class yes로 예측해 버리고 Class no를 하나도 예측을 못 했다고 가정해보자. 이때 accuracy는 10,000분의 9,900이 되서 제대로 예측을 할 수 있다(즉, 99%의 정확도) 겉으로 봐서는 이것은 대단히 좋은 정확도가 될 수가 있다고 착각을 할 수가 있다. 그러나 실제로는 100% 잘못 예측한 것이다. 이러한 이유로 accuracy는 모델의 성능을 측정하는 데 `항상` 적합하지는 않습니다. 따라서 다른 다양한 평가 방법을 통해서 평가를 해볼 필요가 있다는 거죠.\n",
    "\n",
    "\n",
    "3. 저항률 또는 정밀도(Precision)과 재현율(Recall)\n",
    "`저항률(precision)` : 모델이 검출한 데이터 중에서 올바르게 검출된 데이터의 비율.\n",
    "`재현율(recall)` : 데이터 중 올바르게 검출한 데이터의 비율\n",
    "![스크린샷, 2017-09-21 09-45-44](https://i.imgur.com/I0Nm0qz.png)\n",
    "  Precision과 Recall 두 수치가 균형을 모유지하는 모델이 우수한 모델이라고 할 수 있다.\n",
    "\n",
    "![스크린샷, 2017-09-21 09-48-04](https://i.imgur.com/fuIRa9J.png)\n",
    " 이 둘은 반비례하는 관계를 갖는다. 사용자는 위 그래프를 통해서 Precision이 높은 모델을 사용할지, Recall이 높은 모델을 사용할지 선택으 해야 한다. 그러나 이 두 지표도 모델의 성능을 객관적으로 판단하기에는 부족한 부분이 있어 두 가지를 통합하는 척도(F-Masure)가 필요하다.\n",
    "\n",
    "\n",
    "### Learning Cruve\n",
    "모델의 성능을 시각화하여 확인 가능하게 한다.\n",
    "데이터 셋의 크기에 따라 오류 변화를 쉽게 파악할 수 있다.\n",
    "Holdout은 Train Set의 크기가 매우 작을 경우 모델의 오류는 작아지겠지만, Train Set의 크기가 커질 경우에는 오류가 점점 증가한다.\n",
    "\n",
    "반면에 Cross Validation의 경우에는 작은 데이터 셋으로는 오류가 많지만 샘플의 크기가 커질수록 일반화가 되면서 오류가 감소한다.\n",
    "\n",
    "**과소적합의 경우**\n",
    "![스크린샷, 2017-09-21 10-21-43](https://i.imgur.com/YeZ3KIw.png)\n",
    "Holdout방법을 사용하면 Train Set의 크기가 커질수록 오류가 증가하는데, 어느 수치 이상으로는 증가하지 않는다. 반면 Cross Validation의 방법을 사용하면 Train Set의 크기가 커질수록 오류가 감소하지만, 어느 수치 이하로는 감소하지 않는다.\n",
    "\n",
    "**과적합의 경우**\n",
    "![스크린샷, 2017-09-21 10-28-15](https://i.imgur.com/6JuWBwF.png)\n",
    "Holdout과 Cross Validation 방법 간 오차의 차이가 쉽게 좁혀지지 않는다. 데이터 셋의 크기를 키울 경우 이 gap이 좁혀지기는 하지만 과적합 모델의 경우에는 더 많은 데이터를 수집해서 사용하는 것이 필요하다.\n",
    "\n",
    "### ROC Curve\n",
    "ROC(Receiver Operating Characteristic) curve의 TP, FP 수치 입력을 해서 두 수치의 균형을 살펴 볼 수 있다. 각 모델의 성능은 ROC curve 상의 한 점으로 표현한다.\n",
    "\n",
    "Y축 수치 : TP(True Positive Rate)\n",
    "  * Sensitivity(민감도), TPR(True Positive Rate) 전체 yes클래스 데이터 중 모델이 예측한 yes클래스 데이터 비율을 의미하며 `Sensitivity=Recall`값이 Recall값과 일치한다.\n",
    "\n",
    "X축 수치 : FP(False Positive Rate)\n",
    "  * 특이도, TNR(True Negative Rate) yes클래스 데이터 중 모델이 예측한 no 클래스 데이터 비율을 의미한다.\n",
    "  * 특이도를 이용해서 False Positive Rate를 구할 수 있는데, FPR은 실제 no 클래스 데이터 중에서 모델이 yes클래스 데이터의 비율로, `1-specificity`와 같다.\n",
    "\n",
    "  ![스크린샷, 2017-09-21 10-33-48](https://i.imgur.com/S66RcG4.png)\n",
    "  이렇게 구한 두 수치를 사용해 ROC Curve를 그리면 위와 같이 된다. 모델이 yes 클래스를 정확하게 에측할수록 Sensitivity, TPR값이 높아지게 된다.\n",
    "\n",
    "  TPR 값이 높아질수록 ROC Curve와 아래 면적인 AUC가 1에 가까워진다. 이는 모델이 yes클래스를 예측하는 정확도가 높음을 의미한다.\n",
    "\n",
    "### Residual\n",
    "![스크린샷, 2017-09-21 10-35-21](https://i.imgur.com/IfRcfnp.png)\n",
    "  우리말로 -1 오차. 또는 잔차라고 한다. 회귀분석모델에서 예측갑소가 실제값의 차이를 의미하게 된다. 이 잔차의 분포를 나타내느 산포도를 그려볼 수 있는데, 이를 `Residual Plot`이라고 한다. 이 그래프의 세로축은 Residual, 즉 -1 잔차, 가로축은 독립변수가 된다. 이 산포도를 통해서 어떤 모델이 데이터에 적합한지 알 수가 있다.\n",
    "\n",
    "![스크린샷, 2017-09-21 10-37-02](https://i.imgur.com/m87rdxa.png)\n",
    "  우선, 선형모델의 경우 x축을 기준으로 잔차가 랜덤으로 분포하는 모델이 이상적이고, 비선형 모델의 경우 Residual이 일정한 패턴을 보이면서 분포하는 상태가 이상적이다. (두번째, 세번째 그림)\n",
    "\n",
    "![스크린샷, 2017-09-21 10-38-44](https://i.imgur.com/be5ZbtR.png)\n",
    "  이제 Residual을 사용해 구할 수 있는` MSE(Mean Squared Error)`이라고 부르는 평균제곱오차라가 있다. 회귀선과 모델 예측값 사이 오차, Residual을 사용하는데, 오차를 제곱한 값들의 평균이 MSE이다.\n",
    "\n",
    "\n",
    "![스크린샷, 2017-09-21 10-40-07](https://i.imgur.com/b5aQnWm.png)\n",
    "  우선 모델로부터 발생한 다섯 개의 오차가 다음과 같이 있다고 가정을 하겠습니다. 이 `오차 제곱의 평균`을 구하게 되는데요.\n",
    "\n",
    "이 결과값은 2.59가 됩니다. 여기에 루트를 적용하게 되면 이것이 Root Mean Squared Error, 즉 `RMSE`가 됩니다. 앞의 예제의 RMSE 값은 1.6이 되는 거죠. MSE와 RMSE 모두 오차가 줄어들수록 수치도 작아집니다.\n",
    "\n",
    "## 강의 요약\n",
    "\n",
    "이번 시간에는 예측모델의 성능을 평가하는 방법으로 데이터셋을 구성하는 방법과 모델의 성능을 평가하는 척도에 대해 학습했다.\n",
    "\n",
    "* Holdout : 훈련용 데이터, 테스트용 데이터 분리 가능\n",
    "* Random Subsampling : Holdout 반복\n",
    "* Cross Validation : 데이터 셋을 중복하지 않음\n",
    "* Stratified Sampling : 각각 일정 비율의 샘플 추출\n",
    "* Bootstrap : 샘플을 추출할 때, 추출 허용\n",
    "\n",
    "\n",
    "1. 데이터 구성방법에는 3가지\n",
    "![k1](https://i.imgur.com/yP27teN.png)\n",
    "\n",
    "    * Training Set : 기계학습 모델을 훈련시키는데 사용하는 데이터 집합\n",
    "    * Validation Set : 모델이 훈련용 데이터에만 최적화되는 과적합 또는 과소적합 감지를 통해 모델 개선 가능\n",
    "    * Test Set : 모델의 최종 성능 평가\n",
    "\n",
    "2. 모델의 성능을 평가하는 척도 일곱 가지\n",
    "    * 첫 번째, 모델의 성능을 수치로 시각화하는 Confusion Matrix\n",
    "    * 두 번째, 정확도를 나타내는 Accuracy,\n",
    "    * 세 번째, 정확률을 나타내는 Precision\n",
    "    * 네 번째, 재현률을 나타내는 Recall(리콜)\n",
    "    * 다섯번째, F-Measure은 Precision과 Recall 값을 통합한 수치를 나타내는 척도이며, Roc Curve는 모델의 민감도와 특이도가 가지는 관계의 시각적으로 확인할 수 있습니다.\n",
    "    * 여섯번째, RMSE는 모델 예측값의 오차를 계산할 수 있습니다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
